{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Cox Dataset\n",
    "### Author: Divya Veerapaneni MS4, Ong Lab\n",
    "### Description: This ipynb preprocesses the TBI dataset for the Cox model.  \n",
    "### Input: \n",
    "#### all_pupils_bmc.csv - multiple pupil observations per patient\n",
    "#### Consolidated_Study_Cohort_Traits.xlsx - patient-level fixed variables (demographic and pupil data)\n",
    "#### utilizes helper functions from HelperMethods.py\n",
    "### Output: cox dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from scipy.stats import f_oneway\n",
    "import datetime\n",
    "import warnings\n",
    "import statistics\n",
    "import HelperMethods\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read input files as dataframes\n",
    "file_path = '/Users/divs/Box/1-BMC Smartguards/10-Processing and Visualization/8-TBI Pupillometry/Data/Intermediate Datasets/'\n",
    "outcomes_df = pd.read_excel('/Users/divs/Box/1-BMC Smartguards/10-Processing and Visualization/8-TBI Pupillometry/Data/Consolidated_Study_Cohort_Traits.xlsx')\n",
    "pupil_df = pd.read_csv('/Users/divs/Box/1-BMC Smartguards/10-Processing and Visualization/8-TBI Pupillometry/Data/all_pupils_bmc_04-04-2023.csv', low_memory=False)\n",
    "\n",
    "#pre-process pupil dataset\n",
    "pupil_df = pupil_df[pupil_df.mrn.isin(outcomes_df.MRN.to_list())]\n",
    "pupil_df = pupil_df[['mrn', 'date', 'npil', 'sizel','minl', '%l', 'cvl', 'mcvl', 'dvl', 'latl', 'npir', 'sizer', 'minr', '%r', 'cvr', 'mcvr', 'dvr', 'latr']]\n",
    "\n",
    "#pre-process patient dataset\n",
    "outcomes_df = outcomes_df[['MRN', 'ID', 'Crani_Surgery',\n",
    "       'Discharge_Disposition', 'Unfavorable_Outcome',\n",
    "       'Orientedx3', 'Awake_Alert', 'Mechanism_Injury', 'PRES_DT',\n",
    "       'ADMIT_DT', 'DISCH_DT', 'tbi_severity', 'AGE',\n",
    "       'GCS', 'Rotterdam', 'Marshall', 'Mechanism_Injury', 'Deceased', 'RACE_Black']]\n",
    "outcomes_df = outcomes_df.rename(columns={'MRN':'mrn'})\n",
    "\n",
    "#preprocess pupil data\n",
    "cleaned_pupil_df = HelperMethods.clean_tbi_dataframe(pupil_df) #pre_process dataframe\n",
    "cleaned_pupil_df['lower_npi_0_removed'] = cleaned_pupil_df.lower_npi.replace(0, np.nan) #keep only nonzero data\n",
    "cleaned_pupil_df['average_npi_0_removed'] = cleaned_pupil_df.average_npi.replace(0, np.nan) #keep only nonzero data\n",
    "obs_df = HelperMethods.create_first_x_hours_df(cleaned_pupil_df, outcomes_df, 5000) #obtain observations for all patients\n",
    "\n",
    "#compute incidence of abnormal pupil phenotype stages\n",
    "obs_df = obs_df.apply(HelperMethods.compute_incidence, axis=1)\n",
    "\n",
    "#select desired columms (computed per patient/MRN)\n",
    "outcomes_for_obs_df = outcomes_df[['mrn', 'ID', 'Unfavorable_Outcome', 'Deceased', 'Orientedx3', 'Awake_Alert', 'tbi_severity', 'AGE', 'RACE_Black', 'Rotterdam', 'Marshall', 'Mechanism_Injury']]\n",
    "obs_df = obs_df.merge(outcomes_for_obs_df, on ='mrn', how='left')\n",
    "\n",
    "# group by unique mrn and add total observations for each mrn as n_obs\n",
    "grouping = obs_df.groupby(['mrn'])\n",
    "n_obs_df = grouping.size().to_frame('total_obs')\n",
    "obs_df = obs_df.merge(n_obs_df, on='mrn', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute time from discharge\n",
    "outcomes_df.ADMIT_DT = pd.to_datetime(outcomes_df.ADMIT_DT)\n",
    "outcomes_df.DISCH_DT = pd.to_datetime(outcomes_df.DISCH_DT)\n",
    "outcomes_df['time_to_discharge'] = outcomes_df.DISCH_DT - outcomes_df.ADMIT_DT\n",
    "\n",
    "# create df where average pupil metrics is calculated when duplicate observations occur\n",
    "averaged_duplicate_df = obs_df.groupby(['mrn','date'], as_index=False)['average_npi','lower_npi', 'average_npi_0_removed', 'lower_npi_0_removed','npi_diff', 'size_diff'].mean() #took mean pupil metrics of rows where MRN and date same\n",
    "merged_df = obs_df.merge(averaged_duplicate_df, on=['mrn', 'date'], how='left') #merge original df with averaged out pupiil metrics\n",
    "merged_df = merged_df.drop(['average_npi_x','lower_npi_x', 'average_npi_0_removed_x', 'lower_npi_0_removed_x','npi_diff_x', 'size_diff_x', 'total_obs_x'], axis=1) \n",
    "merged_df = merged_df.rename(columns={'average_npi_y': 'average_npi', 'lower_npi_y':'lower_npi', 'average_npi_0_removed_y':'average_npi_0_removed', \\\n",
    "                                      'lower_npi_0_removed_y': 'lower_npi_0_removed','npi_diff_y':'npi_diff', 'size_diff_y':'size_diff', 'total_obs_y':'total_obs'})\n",
    "averaged_df  = merged_df.drop_duplicates(subset=['mrn', 'date'])\n",
    "averaged_df.sort_values(by=['mrn', 'time'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to switch format of column data from sequential values to intervals as follows: ie. col - 1, 2, 5, etc.  ---->  col - 0 to 1, 1 to 2, 2 to 5, etc.\n",
    "def create_start_end_column_version(input_df, col):\n",
    "    start_column_list = []\n",
    "    end_column_list = []\n",
    "    for i in range(len(input_df)):\n",
    "        if i == 0:\n",
    "            start_column_list.append(0)\n",
    "            end_column_list.append(input_df[col].iloc[i])  \n",
    "        elif i < len(input_df):\n",
    "            start_column_list.append(input_df[col].iloc[i-1]) \n",
    "            end_column_list.append(input_df[col].iloc[i])\n",
    "    input_df[col + '_start'] = start_column_list\n",
    "    input_df[col + '_end'] = end_column_list\n",
    "    return input_df\n",
    "\n",
    "#helper function to switch deceased data from 0 to 1 for desired mrns\n",
    "#sets deceased to 1 on very last observation time for patient\n",
    "def helper_create_interval_outcome(df, mrn, mrns_to_change):\n",
    "    input_df = df[df.mrn == mrn]\n",
    "    input_df['Deceased_cox'] = 0\n",
    "    if mrn not in mrns_to_change:\n",
    "        return input_df\n",
    "    else:\n",
    "        input_df.iloc[-1, input_df.columns.get_loc('Deceased_cox')] = 1\n",
    "        return input_df\n",
    "\n",
    "#helper function to iterate through all mrns and change only mrns with bad outcomes\n",
    "def create_interval_outcome(input_df, bad_outcome_pts):\n",
    "    dfs = [helper_create_interval_outcome(input_df, mrn, bad_outcome_pts) for mrn in input_df.mrn.unique()]\n",
    "    final_df = pd.concat(dfs)\n",
    "    return final_df\n",
    "\n",
    "preprocessed_df = averaged_df.copy()\n",
    "preprocessed_df = HelperMethods.create_start_end_column_version(preprocessed_df, 'time') #switch time from sequential to interval formatting\n",
    "pts_deceased = list(preprocessed_df[preprocessed_df.Deceased==1].mrn.unique())\n",
    "final_df = create_interval_outcome(preprocessed_df, pts_deceased) #format deceased column \n",
    "final_df = final_df[['ID', 'time', 'time_start', 'time_end', 'date', 'average_npi', 'lower_npi', 'average_npi_0_removed',\n",
    "       'lower_npi_0_removed', 'npi_diff', 'size_diff',  'any_incidence', 'poor_npi_incidence', 'npi_diff_incidence',\n",
    "       'size_diff_incidence', 'uni_any_incidence', 'stage1u_incidence',\n",
    "       'stage2u_incidence', 'stage3u_incidence', 'stage4u_incidence',\n",
    "       'bi_incidence', 'stage1b_incidence', 'stage2b_incidence',\n",
    "       'stage3b_incidence', 'npi_diff_size_diff_incidence',\n",
    "       'size_diff_poor_npi_incidence', 'Deceased_cox', 'tbi_severity', 'AGE', 'RACE_Black', 'Rotterdam', 'Mechanism_Injury', 'total_obs']]\n",
    "#final_df.to_csv(file_path + 'Cox_9-13.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
